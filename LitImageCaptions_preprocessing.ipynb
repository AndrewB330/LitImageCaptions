{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LitImageCaptions_preprocessing.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1B6V30isZHH"
      },
      "source": [
        "!wget -nc https://github.com/jbrownlee/Datasets/releases/download/Flickr8k/Flickr8k_Dataset.zip\n",
        "!wget -nc https://github.com/jbrownlee/Datasets/releases/download/Flickr8k/Flickr8k_text.zip\n",
        "!unzip -q -o Flickr8k_Dataset.zip\n",
        "!unzip -q -o Flickr8k_text.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KKHGtUsLvjm4"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "from pickle import dump\n",
        "from tensorflow import keras\n",
        "from keras.models import Model\n",
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "from os import listdir\n",
        "\n",
        "from IPython.display import clear_output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lD0lUue8xhQj"
      },
      "source": [
        "image_shape = (224, 224, 3)\n",
        "\n",
        "datase_size = 8091\n",
        "preprocess_batch_size = 3\n",
        "preprocess_batches = datase_size / preprocess_batch_size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i7ZTkU3Jt6Hh"
      },
      "source": [
        "def extract_features(directory):\n",
        "  # load the model\n",
        "  model = keras.applications.vgg16.VGG16()\n",
        "  # re-structure the model\n",
        "  model = Model(inputs=model.inputs, outputs=model.layers[-2].output)\n",
        "  # summarize\n",
        "  # extract features from each photo\n",
        "  features = dict()\n",
        "\n",
        "  batch_data = np.zeros((preprocess_batch_size, 224, 224, 3))\n",
        "  batch_ids = []\n",
        "\n",
        "  for i, name in enumerate(listdir(directory)):\n",
        "    # load an image from file\n",
        "    filename = directory + '/' + name\n",
        "    image = load_img(filename, target_size=(224, 224))\n",
        "    # convert the image pixels to a numpy array\n",
        "    image = img_to_array(image)\n",
        "    # reshape data for the model\n",
        "    batch_data[i % preprocess_batch_size] = image\n",
        "    batch_ids.append(name.split('.')[0])\n",
        "    if len(batch_ids) == preprocess_batch_size:\n",
        "      assert(i % preprocess_batch_size == preprocess_batch_size - 1)\n",
        "      # prepare the image for the VGG model\n",
        "      print(batch_data.max())\n",
        "      batch_data = preprocess_input(batch_data)\n",
        "      print(batch_data.max())\n",
        "      # get features\n",
        "      feature = model.predict(batch_data, verbose=0)\n",
        "      # get image id\n",
        "      # store feature\n",
        "      for j, id in enumerate(batch_ids):\n",
        "        features[id] = feature[j]\n",
        "      batch_index = ((i+1)//preprocess_batch_size)\n",
        "      print(f'Batch #{batch_index}/{preprocess_batches} ready')\n",
        "      batch_ids = []\n",
        "  return features"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZBWpS33uBIp"
      },
      "source": [
        "features_dict = extract_features('./Flicker8k_Dataset')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVOxiWOPwMqQ"
      },
      "source": [
        "def load_doc(filename):\n",
        "\tfile = open(filename, 'r')\n",
        "\ttext = file.read()\n",
        "\tfile.close()\n",
        "\treturn text\n",
        "\n",
        "filename = 'Flickr8k.token.txt'\n",
        "# load descriptions\n",
        "doc = load_doc(filename)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ntN2P0Up1BFG",
        "outputId": "7be01a63-00b8-4de2-ceb9-55932d41836c"
      },
      "source": [
        "# extract descriptions for images\n",
        "def load_descriptions(doc):\n",
        "\tmapping = dict()\n",
        "\t# process lines\n",
        "\tfor line in doc.split('\\n'):\n",
        "\t\t# split line by white space\n",
        "\t\ttokens = line.split()\n",
        "\t\tif len(line) < 2:\n",
        "\t\t\tcontinue\n",
        "\t\t# take the first token as the image id, the rest as the description\n",
        "\t\timage_id, image_desc = tokens[0], tokens[1:]\n",
        "\t\t# remove filename from image id\n",
        "\t\timage_id = image_id.split('.')[0]\n",
        "\t\t# convert description tokens back to string\n",
        "\t\timage_desc = ' '.join(image_desc)\n",
        "\t\t# create the list if needed\n",
        "\t\tif image_id not in mapping:\n",
        "\t\t\tmapping[image_id] = list()\n",
        "\t\t# store description\n",
        "\t\tmapping[image_id].append(image_desc)\n",
        "\treturn mapping\n",
        "\n",
        "# parse descriptions\n",
        "descriptions = load_descriptions(doc)\n",
        "print('Loaded: %d ' % len(descriptions))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded: 8092 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tpRhwWdx2pHW"
      },
      "source": [
        "import string\n",
        "\n",
        "def clean_descriptions(descriptions):\n",
        "\t# prepare translation table for removing punctuation\n",
        "\ttable = str.maketrans('', '', string.punctuation)\n",
        "\tfor key, desc_list in descriptions.items():\n",
        "\t\tfor i in range(len(desc_list)):\n",
        "\t\t\tdesc = desc_list[i]\n",
        "\t\t\t# tokenize\n",
        "\t\t\tdesc = desc.split()\n",
        "\t\t\t# convert to lower case\n",
        "\t\t\tdesc = [word.lower() for word in desc]\n",
        "\t\t\t# remove punctuation from each token\n",
        "\t\t\tdesc = [w.translate(table) for w in desc]\n",
        "\t\t\t# remove hanging 's' and 'a'\n",
        "\t\t\tdesc = [word for word in desc if len(word)>1]\n",
        "\t\t\t# remove tokens with numbers in them\n",
        "\t\t\tdesc = [word for word in desc if word.isalpha()]\n",
        "\t\t\t# store as string\n",
        "\t\t\tdesc_list[i] =  ' '.join(desc)\n",
        "\n",
        "# clean descriptions\n",
        "clean_descriptions(descriptions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K0eYFwPu2zw1",
        "outputId": "2ddf22e5-bd98-4c4b-8748-732703d15064"
      },
      "source": [
        "# convert the loaded descriptions into a vocabulary of words\n",
        "def to_vocabulary(descriptions):\n",
        "\t# build a list of all description strings\n",
        "\tall_desc = set()\n",
        "\tfor key in descriptions.keys():\n",
        "\t\t[all_desc.update(d.split()) for d in descriptions[key]]\n",
        "\treturn all_desc\n",
        "\n",
        "# summarize vocabulary\n",
        "vocabulary = to_vocabulary(descriptions)\n",
        "print('Vocabulary Size: %d' % len(vocabulary))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocabulary Size: 8763\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6SYtW4kx3Cvt"
      },
      "source": [
        "# save descriptions to file, one per line\n",
        "def save_descriptions(descriptions, filename):\n",
        "\tlines = list()\n",
        "\tfor key, desc_list in descriptions.items():\n",
        "\t\tfor desc in desc_list:\n",
        "\t\t\tlines.append(key + ' ' + desc)\n",
        "\tdata = '\\n'.join(lines)\n",
        "\tfile = open(filename, 'w')\n",
        "\tfile.write(data)\n",
        "\tfile.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jE0X76PR3NEV"
      },
      "source": [
        "dump(res, open('features.pickle','wb'))\n",
        "save_descriptions(descriptions, 'descriptions.txt')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}